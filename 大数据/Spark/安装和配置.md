# 生产环境下的hadoop和spark集群搭建

## 通用内容
配置环境变量

同步文件:rsync -av /usr/local/jdk 

给主机命名

添加hadoop用户和sudo权限

免SSH登录

配置防火墙或关闭防火墙

同步时间

## 安装scala  
## 安装jdk
## 安装hadoop
    参考文章 https://blog.csdn.net/hangzhi22/article/details/52560831
    修改配置文件
        core-site.xml
        hdfs-site.xml#
        mapred-site.xml
        yarn-site.xml
        slaves

## 安装spark

# 命令解析

# 运行模式
Spark 有很多种模式，最简单就是单机本地模式，还有单机伪分布式模式，复杂的则运行在集群中，目前能很好的运行在 Yarn和 Mesos 中，当然 Spark 还有自带的 Standalone 模式，对于大多数情况 Standalone 模式就足够了，如果企业已经有 Yarn 或者 Mesos 环境，也是很方便部署的。

standalone类似于MapReduce 1.0所采用扥模式，内部实现了容错性和资源管理，后两种则是未来的发展趋势，部分容错性和资源管理交由统一的资源管理系统完成；让Spark运行在一个通用的资源管理系统之上，这样可以与其他计算框架，比如MapReduce，公用一个集群资源，最大的好处是降低运维成本和提高资源利用率（资源按需分配）

## local（本地模式）
常用于本地开发测试，本地分为local单线程和local-cluster多线程

1.本地模式不运行在集群上，运行在当前执行的机器上
2.本地模式的任务不会在web页面显示
3.本地模式是采用线程来模拟集群的worker进程

本地模式两线程运行
``./bin/run-example SparkPi 10 --master local[2]``

## standalone（集群模式）
典型的Mater/slave模式，不过也能看出Master是有单点故障的；Spark支持ZooKeeper来实现 HA

即独立模式，自带完整的服务，可单独部署到一个集群中，无需依赖任何其他资源管理系统，将Spark standalone与MapReduce比较，会发现它们两个在架构上是完全一致的：

``spark-submit --class org.apache.spark.examples.JavaSparkPi --master spark://Master:7077 /usr/local/spark/examples/jars/spark-examples_2.11-2.3.0.jar 100``

## spark on mesos（集群模式）
由 mesos 负责资源管理，Spark 负责任务调度和计算

这是很多公司采用的模式，官方推荐这种模式（当然，原因之一是血缘关系）。正是由于Spark开发之初就考虑到支持Mesos，因此，目前而言，Spark运行在Mesos上会比运行在YARN上更加灵活，更加自然。目前在Spark On Mesos环境中，用户可选择两种调度模式之一运行自己的应用程序

1)   粗粒度模式（Coarse-grained Mode）：每个应用程序的运行环境由一个Dirver和若干个Executor组成，其中，每个Executor占用若干资源，内部可运行多个Task（对应多少个“slot”）。应用程序的各个任务正式运行之前，需要将运行环境中的资源全部申请好，且运行过程中要一直占用这些资源，即使不用，最后程序运行结束后，回收这些资源。举个例子，比如你提交应用程序时，指定使用5个executor运行你的应用程序，每个executor占用5GB内存和5个CPU，每个executor内部设置了5个slot，则Mesos需要先为executor分配资源并启动它们，之后开始调度任务。另外，在程序运行过程中，mesos的master和slave并不知道executor内部各个task的运行情况，executor直接将任务状态通过内部的通信机制汇报给Driver，从一定程度上可以认为，每个应用程序利用mesos搭建了一个虚拟集群自己使用。 

2)   细粒度模式（Fine-grained Mode）：鉴于粗粒度模式会造成大量资源浪费，Spark On Mesos还提供了另外一种调度模式：细粒度模式，这种模式类似于现在的云计算，思想是按需分配。与粗粒度模式一样，应用程序启动时，先会启动executor，但每个executor占用资源仅仅是自己运行所需的资源，不需要考虑将来要运行的任务，之后，mesos会为每个executor动态分配资源，每分配一些，便可以运行一个新任务，单个Task运行完之后可以马上释放对应的资源。每个Task会汇报状态给Mesos slave和Mesos Master，便于更加细粒度管理和容错，这种调度模式类似于MapReduce调度模式，每个Task完全独立，优点是便于资源控制和隔离，但缺点也很明显，短作业运行延迟大。

## spark on yarn（集群模式）
由 yarn 负责资源管理，Spark 负责任务调度和计算

这是一种很有前景的部署模式。但限于YARN自身的发展，目前仅支持粗粒度模式（Coarse-grained Mode）。这是由于YARN上的Container资源是不可以动态伸缩的，一旦Container启动之后，可使用的资源不能再发生变化，不过这个已经在YARN计划中了。 
spark on yarn 的支持两种模式： 
1) yarn-cluster：适用于生产环境； 
2) yarn-client：适用于交互、调试，希望立即看到app的输出

将Spark作业跑在Yarn上，首先需要启动Yarn集群，然后通过spark-shell或spark-submit的方式将作业提交到Yarn上运行。提交作业之前需要将HADOOP_CONF_DIR或YARN_CONF_DIR配置到Spark-env.sh中：
```
1. vi spark-env.sh
2. HADOOP_CONF_DIR=/opt/software/hadoop-2.6.0-cdh5.7.0/etc/hadoop
```

``spark-submit --class org.apache.spark.examples.JavaSparkPi --master yarn-cluster /usr/local/spark/examples/jars/spark-examples_2.11-2.3.0.jar 100``

## on cloud（集群模式）
比如 AWS 的 EC2，使用这个模式能很方便的访问 Amazon的 S3;Spark 支持多种分布式存储系统：HDFS 和 S3

## 总结
上面涉及到Spark的许多部署模式，究竟哪种模式好这个很难说，需要根据你的需求，如果你只是测试Spark Application，你可以选择local模式。而如果你数据量不是很多，Standalone 是个不错的选择。当你需要统一管理集群资源（Hadoop、Spark等），那么你可以选择Yarn或者mesos，但是这样维护成本就会变高。 
- 从对比上看，mesos似乎是Spark更好的选择，也是被官方推荐的 
- 但如果你同时运行hadoop和Spark,从兼容性上考虑，Yarn是更好的选择。 · 如果你不仅运行了hadoop，spark。还在资源管理上运行了docker，Mesos更加通用。 
- Standalone对于小规模计算集群更适合！

> https://blog.csdn.net/u013063153/article/details/53635845
