

# 基本概念

## Resilient Distributed Dataset (RDD)弹性分布数据集

最主要的一个抽象出来的概念就是分布式的数据集合， 也就是弹性分布式数据集 Resilient Distributed Dataset (RDD)，是对分布式内存的抽象使用，实现了以操作本地集合的方式来操作分布式数据集的抽象实现。

RDD表示已被分区，不可变得并能被并行操作的数据集合，不同数据集格式对应不同的RDD实现。RDD必须是可序列化的。可以cache到内存中。一个RDD对象本质是多个元素的组合。它可以使包含多个元素（元组、列表、字典）的列表。

#### 特点：

是在集群节点上的不可变的、已分区的集合对象。 通过并行转换的方式来创建如（map,filter, join, etc） 。 失败自动重建。 可以控制存储级别（内存、磁盘等） 来进行重用。 必须是可序列化的。 是静态类型的

#### 好处：

RDD只能从持久存储或通过Transformations操作产生，相比于分布式共享内存（DSM） 可以更高效实现容错，对于丢失部分数据分区只需根据它的lineage就可重新计算出来，而不需要做特定的Checkpoint。 RDD的不变性，可以实现类Hadoop MapReduce的推测式执行。 RDD的数据分区特性，可以通过数据的本地性来提高性能，这与Hadoop MapReduce是一样的。 RDD都是可序列化的，在内存不足时可自动降级为磁盘存储，把RDD存储于磁盘上，这时性能会有大的下降但不会差于现在的MapReduce。

#### 存储与分区：

用户可以选择不同的存储级别存储RDD以便重用。 当前RDD默认是存储于内存，但当内存不足时，RDD会spill到disk。 RDD在需要进行分区把数据分布于集群中时会根据每条记录Key进行分区（如Hash 分区） ，以此保证两个数据集在Join时能高效。 RDD的内部表示 在RDD的内部实现中每个RDD都可以使用5个方面的特性来表示： 分区列表（数据块列表） 计算每个分片的函数（根据父RDD计算出此RDD） 对父RDD的依赖列表 对key-value RDD的 Partitioner【可选】 每个数据分片的预定义地址列表(如HDFS上的数据块的地址)

#### 存储级别：

RDD根据useDisk、useMemory、deserialized、replication四个参数的组合提供了11种存储级别

#### 生成

1、从Hadoop文件系统（或与Hadoop兼容的其它存储系统） 输入（例如HDFS） 创建。 2、从父RDD转换得到新RDD

#### 转换与操作

对于RDD可以有两种计算方式：转换（返回值还是一个RDD） 与操作（返回值不是一个 RDD） 。 转换(Transformations) (如：map, filter, groupBy, join等)，Transformations操作是 Lazy的，也就是说从一个RDD转换生成另一个RDD的操作不是马上执行，Spark在遇到 Transformations操作时只会记录需要这样的操作，并不会去执行，需要等到有Actions操作的时候才会真正启动计算过程进行计算。 操作(Actions) (如：count, collect, save等)，Actions 操作会返回结果或把RDD数据写到存储系统中。Actions是触发Spark启动计算的动因。

![spark_process](http://localhost:4000/$res/spark_process.png)

## Lineage（血统）

相比其他In-Memory类数据库或者Cache类系统，Spark的主要区别在于它处理分布式运算环境下的数据容错性（节点实效/数据丢失）问题时采用的方案。为了保证RDD中数据的鲁棒性，RDD数据集通过所谓的血统关系(Lineage)记住了它是如何从其它RDD中演变过来的。相比其它系统的细颗粒度的内存数据更新级别的备份或者LOG机制，RDD的Lineage记录的是粗颗粒度的特定数据转换（Transformation） 操作（filter, map, join etc.)行为。当这个RDD的部分分区数据丢失时，它可以通过Lineage获取足够的信息来重新运算和恢复丢失的数据分区。这种粗颗粒的数据模型，限制了Spark的运用场合，但同时相比细颗粒度的数据模型，也带来了性能的提升。 RDD在Lineage依赖方面分为 两种Narrow Dependencies与Wide Dependencies用来解决数据容错的高效性。NarrowDependencies是指父RDD的每一个分区最多被一个子RDD的分区所用，表现为一个父RDD的分区对应于一个子RDD的分区或多个父RDD的分区对应于一个子RDD的分区，也就是说一个父RDD的一个分区不可能对应一个子RDD的多个分区。Wide Dependencies是指子RDD的分区依赖于父RDD的多个分区或所有分区，也就是说存在一个父RDD的一个分区对应一个子 RDD的多个分区。对与Wide Dependencies，这种计算的输入和输出在不同的节点上， lineage方法对与输入节点完好，而输出节点宕机时，通过重新计算，这种情况下，这种方法容错是有效的，否则无效，因为无法重试，需要向上其祖先追溯看是否可以重试（这就是 lineage，血统的意思） ，Narrow Dependencies对于数据的重算开销要远小于Wide Dependencies的数据重算开销。

## 容错

在RDD计算，通过checkpint进行容错，做checkpoint有两种方式，一个是checkpoint data，一个是logging the updates。用户可以控制采用哪种方式来实现容错，默认是logging theupdates方式，通过记录跟踪所有生成RDD的转换（transformations） 也就是记录每个RDD的 lineage（血统） 来重新计算生成丢失的分区数据。

## 惰性计算（Lazy Evaluation）

RDD 对象分布于很多个部分，我们无法对其进行列表的标准操作，而且 RDD 本身就是为了处理分布式数据开发的。RDD 抽象方式的优势是可以让 Spark 在本地计算机运行。在本地运行时，Spark 把本地计算机的内存划分为很多部分，以模拟在许多机器上进行计算的情境，所以在本地运行时也无需改动代码。Spark RDD 的另一个优点是代码的惰性计算（lazily evaluate） 。Spark 把一个计算拖延到不得不运行的时候。在上面的代码中，直到运行 raw_data.take(5) ，Spark 才把 TSV 文件载入RDD。当 raw_data =sc.textFile(“dail_show.tsv”) 被调用时，创建了一个指向此文件的指针。但只有当 raw_data.take(5) 需要此文件时，文件才真正被读取进 raw_data。本教程以及未来的讲解中会出现更多惰性计算的例子。

## 流水线（Pipelines）

Spark 大量借用了 Hadoop 的 Map-Reduce 模式，但许多地方与 Hadoop 不同。如果你有使用Hadoop 和传统 Map-Reduce 的经验，Cloudera 有一篇很棒的文章探讨这些差异。如果你从没使用过 Map-Reduce 或 Hadoop 也不用担心，本教程会介绍需要了解的概念。使用 Spark 时，需要理解的核心概念是数据流水线（data pipelining） 。Spark 里的每个运算/计算本质是都是一系列步骤（step） 。这些步骤能被连在一起，按顺序运行，形成一个流水线。流水线中的每个步骤返回一个 Python 值（例如Integer） ，一个 Python 数据结构（例如字典） ，或者一个 RDD 对象。首先，我们来看map() 函数。

## 编程接口

Spark通过与编程语言集成的方式暴露RDD的操作，类似于DryadLINQ和FlumeJava，每个数据集都表示为RDD对象，对数据集的操作就表示成对RDD对象的操作。Spark主要的编程语言是Scala，选择Scala是因为它的简洁性（Scala可以很方便在交互式下使用） 和性能（JVM 上的静态强类型语言） 。 Spark和Hadoop MapReduce类似，Master(类似于MapReduce的 Jobtracker)和Workers(Spark的Slave工作节点)组成。用户编写的Spark程序被称为Driver程序，Dirver程序会连接master并定义了对各RDD的转换与操作，而对RDD的转换与操作通过 Scala闭包(字面量函数)来表示，Scala使用Java对象来表示闭包且都是可序列化的，以此把对RDD的闭包操作发送到各Workers节点。 Workers存储着数据分块和享有集群内存，是运行在工作节点上的守护进程，当它收到对RDD的操作时，根据数据分片信息进行本地化数据操作，生成新的数据分片、返回结果或把RDD写入存储系统

