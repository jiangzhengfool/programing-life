~~~
--conf spark.executorEnv.[EnvironmentVariableName] 设置环境变量
--conf spark.yarn.appMasterEnv.[EnvironmentVariableName] 为YARN添加环境变量。在yarn-cluster模式中控制Spark driver的环境变量，在yarn-client模式中只能控制executor启动的环境变量
--executor-cores 每个Executor进程的CPU core数量
--driver-memory 运行sparkContext的Driver所在所占用的内存
--archives ARCHIVES    被每个executor提取到工作目录的档案列表，用逗号隔开
--–py-files 将指定的文件加到search path，以便于之后import之
~~~

[spark submit参数调优](https://blog.csdn.net/chenjieit619/article/details/53421080)

## num-executors
设置该应用总共需要多少executors来执行，一般设置50~100个左右的Executor进程比较合适

## executor-memory
设置每个executor的内存，一般4-8G。`num-executor*executor-memory`的大小绝不能超过队列的内存总大小。

## executor-cores
设置每个executor的cpu核数，决定了每个executor并行执行task的能力，设置为2-4个即可。`num-executor*executor-cores`也不能超过分配队列中cpu核数的大小。

同样得根据不同部门的资源队列来定，可以看看自己的资源队列的最大CPU core限制是多少，再依据设置的Executor数量，来决定每个Executor进程可以分配到几个CPU core。

同样建议，如果是跟他人共享这个队列，那么num-executors * executor-cores不要超过队列总CPU core的1/3~1/2左右比较合适，也是避免影响其他同学的作业运行。

## driver-memory
运行sparkContext的Driver所在所占用的内存，通常不必设置，设置的话1G就足够了

## spark.default.parallelism
500-1000
设置每个stage经TaskScheduler进行调度时生成task的数量，设置为num-executors*executor-cores的2-3倍为宜

## spark.storage.memoryFraction
该参数用于设置RDD持久化数据在Executor内存中能占的比例，默认是0.6。即Executor中可以用来保存持久化的RDD数据默认占了60%。根据Spark应用中RDD持久化操作的多少可以灵活调整这个比例，即持久化需要的内存多久放大此比例，免得内存不够用而不能持久化或转存到磁盘中，如果持久化操作少儿shuffle的操作多则可降低这个值。

## spark.shuffle.memoryFraction
该参数用于设置shuffle过程中一个task拉取到上个stage的task的输出后，进行聚合操作时能够使用的Executor内存的比例，默认是0.2。也就是说，Executor默认只有20%的内存用来进行该操作。shuffle操作在进行聚合时，如果发现使用的内存超出了这个20%的限制，那么多余的数据就会溢写到磁盘文件中去，此时 就会极大地降低性能。

参见spark.shuffle.storageFraction,同理如果RDD持久化操作少而shuffle操作多则赢提高shuffle操作的内存占比，避免shuffle执行过程中内存不够。

## 获取一些值
#### getMaxExecutionMemory
得到Executor中可用执行内存，计算为`(systemMaxMemory * memoryFraction * safetyFraction).toLong`，其中
~~~
   val memoryFraction = conf.getDouble("spark.shuffle.memoryFraction", 0.2)
    val safetyFraction = conf.getDouble("spark.shuffle.safetyFraction", 0.8)
~~~

#### getMaxStorageMemory
最大能存储的内存也就总内存的0.6*0.9=54%
~~~
/**
   * Return the total amount of memory available for the storage region, in bytes.
   */
  private def getMaxStorageMemory(conf: SparkConf): Long = {
    val systemMaxMemory = conf.getLong("spark.testing.memory", Runtime.getRuntime.maxMemory)
    val memoryFraction = conf.getDouble("spark.storage.memoryFraction", 0.6)
    val safetyFraction = conf.getDouble("spark.storage.safetyFraction", 0.9)
    (systemMaxMemory * memoryFraction * safetyFraction).toLong
  }
~~~

> [手把手教你 Spark 性能调优](http://www.importnew.com/26541.html)
> [spark submit参数及调优](https://www.cnblogs.com/haoyy/p/6893943.html)
> [Spark调优-参数及配置](https://blog.csdn.net/njzhujinhua/article/details/79029554)
> [spark submit参数调优](https://blog.csdn.net/chenjieit619/article/details/53421080)
> [Spark调优的策略](https://blog.csdn.net/fanyao4144/article/details/78759931)
> [Spark提交参数说明和常见优化](https://blog.csdn.net/gamer_gyt/article/details/79135118)
> [Spark2.x学习笔记：5、Spark On YARN模式](https://blog.csdn.net/chengyuqiang/article/details/77864246)
> [Spark开发性能调优](https://blog.csdn.net/vinfly_li/article/details/79415342)
> [Spark 学习: spark 原理简述与 shuffle 过程介绍](https://blog.csdn.net/databatman/article/details/53023818)