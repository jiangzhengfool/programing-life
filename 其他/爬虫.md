以下仅仅是自己一些粗浅认识、欢迎补充指正、欢迎进群交流！

掌握一半便能够熟练的开发爬虫玩了。自己正在努力中...

 一、技能列表
1、掌握java、尤其编程网络部分；李刚的java基础至少看了三遍以上；
2、熟悉html、js、 ajax、firedebug
3、网页去重、找到网站特点
4、分布式
5、多线程
6、一种关系型数据库mysql/oraclelserver/mybatis
7、正则表达式、css selector、 xpath
8、DNS cache
9、TCP/IP/Http协议tp2.010、web登录协议
10、 SSO、OAuth原理
11、反爬策略
12、熟悉httpClient、okhttp3...
13、 熟悉一些提取工具、jsoup、selenim WebDriver...
14、搜索技术。熟悉Lucene/Nutch/Heritrix/solr/elastic-search/
15、熟悉XML、JSON、SOAP协议；
16、mongodb、 redis、 hbase、 hadoop
17、文本分析、机器学习、数据挖掘、自然语言处理[NLP]
18、完成网页、微博、微信、贴吧、论坛等数据信息的精准抽取
19、RPC协议
20、netty、NIO
21、HTMLUnit、PhantomJS、SlimerJS 、CasperJS
22、代理部署方案:http/socks
23、nginx、 squid、jetty
24、破解ios
25、验证码、ocr、tess4j

 

二、爬虫工具
1、Phantomjs

2、berserkJS(基于Phantomjs的改进版本)

3、SlimerJS

4、CasperJS

5、selenium

三、Java相关
常用的IDE：IntelliJ IDEA，Eclipse，Netbeans

Web开发相关：Tomcat、Resin、Jetty、WebLogic等，常用的组件Struts，Spring

HibernateNetty: 异步事件驱动网络应用编程框架，用于高并发网络编程比较好（NIO框架）

MINA：简单地开发高性能和高可靠性的网络应用程序（也是个NIO框架），不少手游服务端是用它开发的

jOOQ：java Orm框架Activiti:工作流引擎，类似的还有jBPM、Snaker

Perfuse:是一个用户界面包用来把有结构与无结构数据以具有交互性的可视化图形展示出来.

Gephi:复杂网络分析软件, 其主要用于各种网络和复杂系统，动态和分层图的交互可视化与探测开源工具

Nutch:知名的爬虫项目，hadoop就是从这个项目中发展出来的

web-harvest：Web数据提取工具

POM工具：Maven+ArtifactoryNetflix

Curator：Netflix公司开源的一个Zookeeper client library，用于简化Zookeeper客户端编程

Akka:一款基于actor模型实现的 并发处理框架

EclEmma：覆盖测试工具




1. 谈爬虫工程师的价值 
    大数据时代已到，数据越来越具有价值了，没有数据寸步难行，有了数据好好利用，可以在诸多领域干很多事，比如很火的互联网金融。从互联网上爬来自己想要的数据，是数据的一个重要来源，而且往往是必不可少的来源。所有，目前，爬虫工程师是一个非常吃香的职位，工资往往都不低，就是要耐得住寂寞了。那爬虫工程师的价值也就是能稳定的、高效的和实时的带来数据。这里推荐看两篇文章： 
http://www.hzzx.gov.cn/cshz/content/2014-08/25/content_5417124.htm 
http://www.tuicool.com/articles/Fb6fy2f 
2. 爬虫（或互联网数据采集）怎么入门 
     爬虫可以很快的入门，但要做的真正大神，还必须不断实践。因为，一旦真正爬数据的时候就会出现各种问题，因为爬虫本质是一种对抗性的工作，你需要和反爬人员斗智斗勇。不过，这个过程会充满无穷的乐趣，还会把你锤炼成真正的爬虫高手。 
3. 专门为爬虫入门而写的知乎爬虫 
     这里，耗费了不少的业余时间，专门为爬虫入门写了一个知乎爬虫。为什么选择知乎呢？应为这里例子可以尽量多的将爬虫涉及的技术点包含进去，同时又不至于那么复杂，方便入门。下面说明知乎爬虫的源码和涉及主要技术点： 

模拟登录（爬虫主要技术点1） 
    要爬去需要登录的网站数据，模拟登录是必要可少的一步，而且往往是难点。知乎爬虫的模拟登录可以做一个很好的案例。要实现一个网站的模拟登录，需要两大步骤是：（1）对登录的请求过程进行分析，找到登录的关键请求和步骤，分析工具可以有IE自带(快捷键F12)、Fiddler、HttpWatcher；（2）编写代码模拟登录的过程。 

网页下载（爬虫主要技术点2） 
    模拟登录后，便可下载目标网页html了。知乎爬虫基于HttpClient写了一个网络连接线程池，并且封装了常用的get和post两种网页下载的方法。 

自动获取网页编码（爬虫主要技术点3） 
自动获取网页编码是确保下载网页html不出现乱码的前提。知乎爬虫中提供方法可以解决绝大部分乱码下载网页乱码问题。 

  网页解析和提取（爬虫主要技术点4） 
使用Java写爬虫，常见的网页解析和提取方法有两种：利用开源Jar包Jsoup和正则。一般来说，Jsoup就可以解决问题，极少出现Jsoup不能解析和提取的情况。Jsoup强大功能，使得解析和提取异常简单。知乎爬虫采用的就是Jsoup。 
                                    
  正则匹配与提取（爬虫主要技术点5） 
    虽然知乎爬虫采用Jsoup来进行网页解析，但是仍然封装了正则匹配与提取数据的方法，因为正则还可以做其他的事情，如在知乎爬虫中使用正则来进行url地址的过滤和判断。 

  数据去重（爬虫主要技术点6） 
    对于爬虫，更具场景不同，可以有不同的去重方案。（1）少量数据，比如几万或者十几万条的情况，使用Map或Set便可；（2）中量数据，比如几百万或者上千万，使用BloomFilter（著名的布隆过滤器）可以解决；（3）大量数据，上亿或者几十亿，Redis可以解决。知乎爬虫给出了BloomFilter的实现，但是采用的Redis进行去重。 

    除了以上爬虫主要的技术点之外，知乎爬虫的实现还涉及多种设计模式，主要有链模式、单例模式、组合模式等，同时还使用了Java反射。除了学习爬虫技术，这对学习设计模式和Java反射机制也是一个不错的案例。 
 
http://blog.sina.com.cn/s/blog_6b8c15570102w195.html
爬虫工程师











爬虫技能:
基础:java语言
1.Jsoup
2.选择器的使用

> [Jsoup学习总结](https://blog.csdn.net/u010814849/article/details/52526582)